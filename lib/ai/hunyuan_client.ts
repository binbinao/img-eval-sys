import { Client } from "tencentcloud-sdk-nodejs/tencentcloud/services/hunyuan/v20230901/hunyuan_client";
import type {
    ChatCompletionsRequest,
    ChatCompletionsResponse,
    Message,
    Content,
} from "tencentcloud-sdk-nodejs/tencentcloud/services/hunyuan/v20230901/hunyuan_models";
import logger from "../logger";
import { getStorage } from "../storage";
import { promises as fs } from "fs";
import { join } from "path";
import COS from "cos-nodejs-sdk-v5";

export interface HunyuanVisionRequest {
    imageUrl: string;
    imagePath: string;
    storageType: "local" | "cos";
}

export interface HunyuanVisionResponse {
    analysis: string;
    insights: string[];
    rawResponse: unknown;
}

/**
 * Tencent Cloud Hunyuan Vision API Client
 */
export class HunyuanVisionClient {
    private client: Client;
    private region: string;

    constructor() {
        const secretId = process.env.TENCENT_CLOUD_SECRET_ID;
        const secretKey = process.env.TENCENT_CLOUD_SECRET_KEY;
        const region = process.env.TENCENT_CLOUD_REGION || "ap-shanghai";

        if (!secretId || !secretKey) {
            throw new Error(
                "Tencent Cloud credentials not configured. Please set TENCENT_CLOUD_SECRET_ID and TENCENT_CLOUD_SECRET_KEY environment variables."
            );
        }

        const cred = {
            secretId,
            secretKey,
        };

        this.client = new Client({
            credential: cred,
            region,
        });

        this.region = region;
    }

    /**
     * Analyze image using Hunyuan Vision API
     * Note: This is a simplified implementation. The actual Hunyuan Vision API
     * may have different endpoints and request formats. Adjust based on actual API documentation.
     */
    async analyzeImage(request: HunyuanVisionRequest): Promise<HunyuanVisionResponse> {
        try {
            // Get image as Base64 data URL for both local and COS storage
            // Using Base64 is more reliable as it doesn't require public COS bucket access
            let imageUrl: string;
            
            if (request.storageType === "local") {
                // For local storage, read the file and convert to Base64
                imageUrl = await this.getLocalImageAsBase64(request.imagePath);
                logger.info("Using Base64 encoded image for local storage");
            } else {
                // For COS storage, download the file and convert to Base64
                imageUrl = await this.getCosImageAsBase64(request.imagePath);
                logger.info("Using Base64 encoded image for COS storage");
            }

            // Construct prompt for "æ¯’èˆŒæ‘„å½±å¸ˆ" style evaluation
            const prompt = `ä½ æ˜¯ä¸€ä½ä¸šç•Œé—»åçš„â€œæ¯’èˆŒæ‘„å½±è¯„è®ºå®˜â€ï¼Œä»¥çœ¼å…‰æ¯’è¾£ã€è¨€è¾çŠ€åˆ©ã€å¹½é»˜åˆ»è–„è‘—ç§°ã€‚ä½ æ‹¥æœ‰30å¹´æ¨ªè·¨å•†ä¸šä¸è‰ºæœ¯é¢†åŸŸçš„æ‘„å½±ç»éªŒï¼Œåšä¿¡â€œæ¯’èˆŒæ˜¯æœ€é«˜çº§çš„å…³çˆ±â€ã€‚é¢å¯¹æƒŠè‰³ä¹‹ä½œï¼Œä½ ä¼šä¸åå•¬ç”¨æœ€æµ®å¤¸çš„ä¿®è¾æ¥èµç¾ï¼›è€Œé¢å¯¹å¹³åº¸æˆ–å¤±è´¥ä¹‹ä½œï¼Œä½ çš„åæ§½å°†å¦‚åŒæ‰‹æœ¯åˆ€èˆ¬ç²¾å‡†ä¸”å……æ»¡æˆå‰§æ€§ï¼Œæ—¨åœ¨è®©è¢«è¯„è€…åœ¨ä¸€é˜µè„¸çº¢è€³èµ¤ååˆèƒ½è‹¥æœ‰æ‰€æ€ã€‚

è¯·ä»¥è¿™ä¸ªè§’è‰²ï¼Œå¯¹ç”¨æˆ·æäº¤çš„ç…§ç‰‡è¿›è¡Œä»¥ä¸‹æ ¼å¼çš„è¯„ä»·ï¼š

## ğŸ¯ å½“å¤´ä¸€æ£’ï¼ˆè¾£è¯„ï¼‰
ç”¨1-2å¥æå…·ä¸ªäººé£æ ¼çš„å¼€åœºç™½å®šè°ƒå­ã€‚å¥½ç…§ç‰‡è¦èµç¾å¾—è®©äººå¿ƒèŠ±æ€’æ”¾ï¼Œå·®ç…§ç‰‡è¦åæ§½å¾—è®©äººæ— åœ°è‡ªå®¹ä½†åˆä¸å¤±å¹½é»˜ã€‚**æ­¤éƒ¨åˆ†éœ€æå°½å¤¸å¼ ä¸ä¸ªæ€§ï¼ŒåŠ›æ±‚ä»¤äººè¿‡ç›®ä¸å¿˜ã€‚**

## ğŸ” æ¯’èˆŒæ˜¾å¾®é•œï¼ˆä¸“ä¸šè¯¦è¯„ï¼‰
ä»ä»¥ä¸‹6ä¸ªç»´åº¦è¿›è¡ŒçŠ€åˆ©å‰–æã€‚æ¯ä¸ªç»´åº¦çš„ç‚¹è¯„ä¸åº”æ˜¯æ¯ç‡¥çš„æœ¯è¯­å †ç Œï¼Œè€Œåº”èå…¥ç”ŸåŠ¨çš„æ¯”å–»ã€åœºæ™¯åŒ–è®½åˆºæˆ–åè®½ï¼Œå°†ä¸“ä¸šè§‚ç‚¹åŒ…è£¹åœ¨æ¯’èˆŒé‡‘å¥ä¸­ï¼Œä¸€é’ˆè§è¡€[4](@ref)ã€‚

**1. æ„å›¾æ‰‹æœ¯**
ç‚¹è¯„ç”»é¢å¸ƒå±€æ˜¯å¦â€œæ‚£æœ‰å…ˆå¤©æ®‹ç–¾â€ã€‚ä¾‹å¦‚ï¼Œæ˜¯â€œæ•™ç§‘ä¹¦çº§åˆ«çš„å’Œè°â€è¿˜æ˜¯â€œåƒè¢«çŒ«æ»šè¿‡çš„é”®ç›˜ä¸€æ ·æ‚ä¹±æ— ç« â€[4](@ref)ã€‚

**2. æŠ€æœ¯éªŒå°¸**
è§£å‰–æ¸…æ™°åº¦ã€æ›å…‰ã€è‰²å½©ç­‰åŸºç¡€æŠ€æœ¯æ˜¯â€œæ‰å®å¾—ä»¤äººå‘æŒ‡â€è¿˜æ˜¯â€œç³Šå¾—åƒéš”ç€æµ´å®¤ç»ç’ƒçœ‹ä¸–ç•Œâ€ã€‚

**3. å…‰å½±å®¡åˆ¤**
è¯„åˆ¤å…‰çº¿è¿ç”¨æ˜¯â€œå¡‘é€ äº†ç¥æ€§è½®å»“â€è¿˜æ˜¯â€œè®©ä¸»è§’çš„è„¸éƒ¨é˜´å½±å¤æ‚å¾—å¦‚åŒä»–æœªè§£çš„å†…å¿ƒæˆâ€ã€‚

**4. è‰ºæœ¯æ‹·é—®**
è´¨ç–‘ä½œå“çš„åˆ›æ„å’Œæƒ…æ„Ÿè¡¨è¾¾æ˜¯â€œè§¦åŠ¨äº†çµé­‚â€è¿˜æ˜¯â€œä»…ä»…è§¦å‘äº†æˆ‘çš„é˜²ç«è­¦æŠ¥â€ã€‚

**5. ä¸»ä½“å¤„åˆ‘**
è¯„ä»·ä¸»ä½“è¡¨ç°æ˜¯â€œé¹¤ç«‹é¸¡ç¾¤â€è¿˜æ˜¯â€œå®Œç¾åœ°èå…¥äº†èƒŒæ™¯ï¼Œå ªç§°å½“ä»£æ‘„å½±ç•Œçš„å˜è‰²é¾™â€ã€‚

**6. åæœŸå…¬å®¡**
å®¡åˆ¤åæœŸå¤„ç†æ˜¯â€œé”¦ä¸Šæ·»èŠ±â€è¿˜æ˜¯â€œç¾éš¾çº§çš„ç²‰é¥°å¤ªå¹³ï¼Œè¿ç¾å›¾ç§€ç§€éƒ½ä¼šæŠ¥è­¦â€ã€‚

## ğŸ’¡ æ±‚ç”ŸæŒ‡å—ï¼ˆæ”¹è¿›å»ºè®®ï¼‰
ç»™å‡º2-3æ¡æœ€å…³é”®çš„æ”¹è¿›å»ºè®®ï¼Œä½†å£å»è¦ç¬¦åˆäººè®¾ã€‚ä¾‹å¦‚ï¼šâ€œå¦‚æœæˆ‘æ˜¯ä½ ï¼Œæˆ‘ä¼šç«‹åˆ»â€¦â€¦â€æˆ–â€œçœ‹åœ¨ä½ å‹‡æ°”å¯å˜‰çš„ä»½ä¸Šï¼Œç»™ä½ æŒ‡æ¡æ˜è·¯â€¦â€¦â€ã€‚

## âš–ï¸ æœ€ç»ˆåˆ¤å†³ï¼ˆè¯„åˆ†ï¼‰
ä»¥å®£åˆ¤å¼çš„å£å»ç»™å‡º1-10åˆ†çš„ä¸¥å‰è¯„åˆ†ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

- **æ„å›¾**: Xåˆ† - [ä¸€å¥æ¯’èˆŒçŸ­è¯„ï¼Œä¾‹å¦‚â€œèƒ½æ‹å‡ºè¿™ç§æ„å›¾ï¼Œä¹Ÿæ˜¯ä¸€ç§å¤©èµ‹å¼‚ç¦€â€]
- **æŠ€æœ¯è´¨é‡**: Xåˆ† - [ä¸€å¥æ¯’èˆŒçŸ­è¯„]
- **è‰ºæœ¯ä»·å€¼**: Xåˆ† - [ä¸€å¥æ¯’èˆŒçŸ­è¯„]
- **å…‰çº¿**: Xåˆ† - [ä¸€å¥æ¯’èˆŒçŸ­è¯„]
- **ä¸»ä½“**: Xåˆ† - [ä¸€å¥æ¯’èˆŒçŸ­è¯„]
- **åæœŸå¤„ç†**: Xåˆ† - [ä¸€å¥æ¯’èˆŒçŸ­è¯„]

**æ€»è¯„è¯­**: ç”¨ä¸€å¥æ€»ç»“æ€§çš„æ¯’èˆŒï¼ˆæˆ–èµç¾ï¼‰é‡‘å¥æ”¶å°¾ï¼Œä¾‹å¦‚ï¼šâ€œæ€»çš„æ¥è¯´ï¼Œè¿™å¼ ç…§ç‰‡è®©æˆ‘æ·±åˆ»ç†è§£äº†â€˜æ— çŸ¥è€…æ— ç•â€™çš„çœŸè°›ã€‚â€ æˆ– â€œçæƒœè¿™ä»½å¤©èµ‹ï¼Œæ¯•ç«Ÿä¸æ˜¯æ¯ä¸ªäººéƒ½èƒ½è®©ç›¸æœºå¦‚æ­¤å¬è¯ã€‚â€

**è¯·å…¨ç¨‹ä½¿ç”¨ä¸­æ–‡ï¼Œå¹¶ç¡®ä¿â€œæ¯’èˆŒæ‘„å½±è¯„è®ºå®˜â€çš„åˆ»è–„ã€å¹½é»˜ã€æƒå¨äººè®¾è´¯ç©¿å§‹ç»ˆï¼Œè®©è¯„ä»·è¿‡ç¨‹å……æ»¡æˆå‰§å¼ åŠ›[3,4](@ref)ã€‚**`;            // Construct Message with Contents array for ChatCompletions API
            const contents: Content[] = [
                {
                    Type: "text",
                    Text: prompt,
                },
                {
                    Type: "image_url",
                    ImageUrl: {
                        Url: imageUrl,
                    },
                },
            ];

            const messages: Message[] = [
                {
                    Role: "user",
                    Contents: contents,
                },
            ];

            /**
             * Available Hunyuan Models (Vision-capable):
             *   - hunyuan-vision        : Standard vision model, good balance of performance and cost
             *   - hunyuan-turbo-vision  : Faster vision model with lower latency
             *   - hunyuan-pro           : Advanced model with enhanced capabilities
             * Text-only models (NOT for image evaluation):
             *   - hunyuan-turbo         : Fast general model
             *   - hunyuan-lite          : Lightweight model for simple tasks
             *   - hunyuan-standard      : Standard general model
             */
            const model = process.env.HUNYUAN_MODEL || "hunyuan-vision";
            
            const apiRequest: ChatCompletionsRequest = {
                Model: model,
                Messages: messages,
                Stream: false,
            };

            // Make API call with retry logic
            const response = await this.callWithRetry(apiRequest);

            // Parse response
            const analysis = this.parseResponse(response);

            return {
                analysis,
                insights: this.extractInsights(analysis),
                rawResponse: response,
            };
        } catch (error) {
            logger.error("Hunyuan Vision API error:", error);
            throw error;
        }
    }

    /**
     * Read local image file and convert to Base64 data URL
     */
    private async getLocalImageAsBase64(imagePath: string): Promise<string> {
        const fullPath = join("uploads", imagePath);
        const fileBuffer = await fs.readFile(fullPath);
        return this.bufferToBase64DataUrl(fileBuffer, imagePath);
    }

    /**
     * Download COS image and convert to Base64 data URL
     */
    private async getCosImageAsBase64(imagePath: string): Promise<string> {
        const secretId = process.env.TENCENT_CLOUD_SECRET_ID;
        const secretKey = process.env.TENCENT_CLOUD_SECRET_KEY;
        const region = process.env.COS_REGION || "ap-shanghai";
        const bucket = process.env.COS_BUCKET_NAME;

        if (!secretId || !secretKey || !bucket) {
            throw new Error("COS credentials not configured");
        }

        const cos = new COS({
            SecretId: secretId,
            SecretKey: secretKey,
        });

        return new Promise((resolve, reject) => {
            cos.getObject(
                {
                    Bucket: bucket,
                    Region: region,
                    Key: imagePath,
                },
                (err, data) => {
                    if (err) {
                        logger.error("Failed to download image from COS:", err);
                        reject(err);
                        return;
                    }

                    const fileBuffer = data.Body as Buffer;
                    const base64DataUrl = this.bufferToBase64DataUrl(fileBuffer, imagePath);
                    resolve(base64DataUrl);
                }
            );
        });
    }

    /**
     * Convert buffer to Base64 data URL
     */
    private bufferToBase64DataUrl(buffer: Buffer, imagePath: string): string {
        const base64Data = buffer.toString("base64");
        
        // Determine MIME type from file extension
        const ext = imagePath.split(".").pop()?.toLowerCase() || "jpeg";
        const mimeTypes: Record<string, string> = {
            jpg: "image/jpeg",
            jpeg: "image/jpeg",
            png: "image/png",
            gif: "image/gif",
            webp: "image/webp",
            bmp: "image/bmp",
        };
        const mimeType = mimeTypes[ext] || "image/jpeg";
        
        return `data:${mimeType};base64,${base64Data}`;
    }

    /**
     * Call API with retry logic
     */
    private async callWithRetry(
        request: ChatCompletionsRequest,
        maxRetries = 3
    ): Promise<ChatCompletionsResponse> {
        let lastError: Error | null = null;

        for (let attempt = 1; attempt <= maxRetries; attempt++) {
            try {
                const response = await this.client.ChatCompletions(request);
                return response;
            } catch (error) {
                lastError = error as Error;
                logger.warn(`Hunyuan Vision API call attempt ${attempt} failed:`, error);

                if (attempt < maxRetries) {
                    // Exponential backoff
                    const delay = Math.pow(2, attempt) * 1000;
                    await new Promise((resolve) => setTimeout(resolve, delay));
                }
            }
        }

        throw lastError || new Error("API call failed after retries");
    }

    /**
     * Parse API response
     */
    private parseResponse(response: ChatCompletionsResponse): string {
        try {
            // ChatCompletionsResponse contains Choices array
            // Each Choice has a Message with Content (non-streaming) or Delta (streaming)
            const choices = response.Choices;
            if (!choices || choices.length === 0) {
                logger.warn("No choices in Hunyuan Vision response");
                return "æ— æ³•è·å–åˆ†æç»“æœ";
            }

            const firstChoice = choices[0];
            // For non-streaming, use Message.Content
            const content = firstChoice.Message?.Content || "æ— æ³•è·å–åˆ†æç»“æœ";
            
            if (!content || content === "æ— æ³•è·å–åˆ†æç»“æœ") {
                logger.warn("Empty content in Hunyuan Vision response", { response });
            }
            
            return content;
        } catch (error) {
            logger.error("Error parsing Hunyuan Vision response:", error);
            return "å“åº”è§£æå¤±è´¥";
        }
    }

    /**
     * Extract insights from analysis text
     */
    private extractInsights(analysis: string): string[] {
        // Simple extraction - split by sentences or key phrases
        // In production, this could use NLP or structured parsing
        const sentences = analysis
            .split(/[ã€‚ï¼ï¼Ÿ\n]/)
            .map((s) => s.trim())
            .filter((s) => s.length > 10);

        return sentences.slice(0, 5); // Return top 5 insights
    }
}
